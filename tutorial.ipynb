{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "def visualize_labeled_images(images, labels, max_outputs=3, name=\"image\"):\n",
    "    def _visualize_image(image, label):\n",
    "        # Do the actual drawing in python\n",
    "        fig = plt.figure(figsize=(3, 3), dpi=80)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.imshow(image[::-1,...])\n",
    "        ax.text(0, 0, str(label),\n",
    "          horizontalalignment=\"left\",\n",
    "          verticalalignment=\"top\")\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        # Write the plot as a memory file.\n",
    "        buf = io.BytesIO()\n",
    "        data = fig.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Read the image and convert to numpy array\n",
    "        img = PIL.Image.open(buf)\n",
    "        return np.array(img.getdata()).reshape(img.size[0], img.size[1], -1)\n",
    "\n",
    "    def _visualize_images(images, labels):\n",
    "        # Only display the given number of examples in the batch\n",
    "        outputs = []\n",
    "        for i in range(max_outputs):\n",
    "            output = _visualize_image(images[i], labels[i])\n",
    "            outputs.append(output)\n",
    "        return np.array(outputs, dtype=np.uint8)\n",
    "\n",
    "    # Run the python op.\n",
    "    figs = tf.py_func(_visualize_images, [images, labels], tf.uint8)\n",
    "    return tf.summary.image(name, figs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8794421   2.20649838 -0.06778084  0.39704013 -1.04980946 -0.00227016\n",
      "  1.76720178  0.9822911  -0.33456507  1.28294444]\n",
      "4.81605529785e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import uuid\n",
    "\n",
    "def relu(inputs):\n",
    "    # Define the op in python\n",
    "    def _relu(x):\n",
    "        return np.maximum(x, 0.)\n",
    "\n",
    "    # Define the op's gradient in python\n",
    "    def _relu_grad(x):\n",
    "        return np.float32(x > 0)\n",
    "\n",
    "    # An adapter that defines a gradient op compatible with TensorFlow\n",
    "    def _relu_grad_op(op, grad):\n",
    "        x = op.inputs[0]\n",
    "        x_grad = grad * tf.py_func(_relu_grad, [x], tf.float32)\n",
    "        return x_grad\n",
    "\n",
    "    # Register the gradient with a unique id\n",
    "    grad_name = \"MyReluGrad_\" + str(uuid.uuid4())\n",
    "    tf.RegisterGradient(grad_name)(_relu_grad_op)\n",
    "\n",
    "    # Override the gradient of the custom op\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": grad_name}):\n",
    "        output = tf.py_func(_relu, [inputs], tf.float32)\n",
    "    return output\n",
    "\n",
    "x = tf.random_normal([10])\n",
    "y = relu(x * x)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(x))\n",
    "\n",
    "with tf.Session():\n",
    "    diff = tf.test.compute_gradient_error(x, [10], y, [10])\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.698e+06\n",
      "1.18267e+06\n",
      "1.48117e+06\n",
      "1.82511e+06\n",
      "1.4511e+06\n",
      "1.21819e+06\n",
      "954477.0\n",
      "1.21098e+06\n",
      "830158.0\n",
      "994920.0\n",
      "1.01736e+06\n",
      "1.15177e+06\n",
      "717129.0\n",
      "795113.0\n",
      "695252.0\n",
      "716860.0\n",
      "774760.0\n",
      "613059.0\n",
      "477241.0\n",
      "615982.0\n",
      "496349.0\n",
      "333458.0\n",
      "349744.0\n",
      "352581.0\n",
      "332616.0\n",
      "328877.0\n",
      "213373.0\n",
      "249426.0\n",
      "236117.0\n",
      "179763.0\n",
      "158730.0\n",
      "136573.0\n",
      "135662.0\n",
      "156774.0\n",
      "135024.0\n",
      "83963.8\n",
      "76199.2\n",
      "67181.3\n",
      "66498.4\n",
      "66240.2\n",
      "52592.4\n",
      "42577.1\n",
      "37470.5\n",
      "20062.0\n",
      "24476.3\n",
      "17376.7\n",
      "16458.2\n",
      "15182.5\n",
      "10025.0\n",
      "9966.22\n",
      "7008.33\n",
      "3530.88\n",
      "3793.49\n",
      "2801.26\n",
      "1644.25\n",
      "941.685\n",
      "705.713\n",
      "548.294\n",
      "330.156\n",
      "197.663\n",
      "227.215\n",
      "231.358\n",
      "190.042\n",
      "267.253\n",
      "388.512\n",
      "404.011\n",
      "550.468\n",
      "509.054\n",
      "641.959\n",
      "680.842\n",
      "754.341\n",
      "921.113\n",
      "837.668\n",
      "940.415\n",
      "1108.2\n",
      "749.364\n",
      "935.319\n",
      "1101.36\n",
      "871.729\n",
      "739.646\n",
      "802.689\n",
      "638.481\n",
      "679.37\n",
      "852.736\n",
      "776.858\n",
      "525.472\n",
      "714.215\n",
      "487.358\n",
      "573.985\n",
      "501.287\n",
      "470.116\n",
      "330.908\n",
      "391.958\n",
      "204.503\n",
      "217.275\n",
      "168.681\n",
      "174.7\n",
      "125.755\n",
      "113.306\n",
      "92.2854\n",
      "80.327\n",
      "67.8356\n",
      "54.7773\n",
      "44.8386\n",
      "37.5437\n",
      "29.7805\n",
      "26.0887\n",
      "22.2388\n",
      "22.6473\n",
      "18.1982\n",
      "18.0468\n",
      "19.0233\n",
      "17.7504\n",
      "21.0889\n",
      "20.9108\n",
      "20.3188\n",
      "23.9678\n",
      "23.8632\n",
      "23.0288\n",
      "28.7161\n",
      "18.5568\n",
      "23.8605\n",
      "29.1898\n",
      "27.8217\n",
      "28.8262\n",
      "30.2917\n",
      "24.1346\n",
      "24.0661\n",
      "25.2504\n",
      "27.0253\n",
      "24.8739\n",
      "21.092\n",
      "20.2502\n",
      "22.1242\n",
      "25.4417\n",
      "20.5147\n",
      "20.6522\n",
      "19.8296\n",
      "20.5432\n",
      "19.9137\n",
      "19.9457\n",
      "19.6183\n",
      "19.6065\n",
      "18.4673\n",
      "18.2716\n",
      "18.7959\n",
      "19.2393\n",
      "18.4546\n",
      "17.6622\n",
      "19.8204\n",
      "17.9798\n",
      "19.7036\n",
      "16.9695\n",
      "17.3581\n",
      "15.4997\n",
      "16.9488\n",
      "18.7131\n",
      "14.9484\n",
      "17.9719\n",
      "19.289\n",
      "18.9912\n",
      "16.6532\n",
      "16.6216\n",
      "17.6542\n",
      "17.1916\n",
      "16.5168\n",
      "18.0752\n",
      "16.2798\n",
      "16.7119\n",
      "18.0238\n",
      "17.6539\n",
      "16.0815\n",
      "16.4374\n",
      "14.8406\n",
      "15.521\n",
      "16.2454\n",
      "16.7082\n",
      "17.4179\n",
      "14.7986\n",
      "15.2484\n",
      "17.6991\n",
      "17.4571\n",
      "16.9454\n",
      "16.9308\n",
      "16.5252\n",
      "15.1292\n",
      "16.8118\n",
      "16.3746\n",
      "17.0539\n",
      "17.5613\n",
      "16.4509\n",
      "14.0741\n",
      "15.2691\n",
      "16.4974\n",
      "15.8727\n",
      "17.6664\n",
      "19.4708\n",
      "16.3118\n",
      "18.2727\n",
      "16.1069\n",
      "15.6976\n",
      "14.9574\n",
      "17.5117\n",
      "14.5613\n",
      "16.7619\n",
      "14.3897\n",
      "16.642\n",
      "15.8629\n",
      "14.9459\n",
      "14.5884\n",
      "15.6372\n",
      "15.9248\n",
      "14.0258\n",
      "15.5138\n",
      "16.0545\n",
      "15.711\n",
      "15.4842\n",
      "14.1869\n",
      "16.335\n",
      "15.1529\n",
      "14.9397\n",
      "17.013\n",
      "16.2304\n",
      "17.5842\n",
      "14.1751\n",
      "14.8867\n",
      "15.2884\n",
      "14.3992\n",
      "13.4971\n",
      "14.5492\n",
      "15.0035\n",
      "14.5736\n",
      "14.2638\n",
      "15.8268\n",
      "13.0626\n",
      "15.3679\n",
      "14.2361\n",
      "15.8733\n",
      "15.8325\n",
      "15.5925\n",
      "14.7975\n",
      "14.6084\n",
      "15.0825\n",
      "13.117\n",
      "15.1809\n",
      "13.1601\n",
      "14.2844\n",
      "15.255\n",
      "14.0685\n",
      "15.3459\n",
      "13.9556\n",
      "15.0863\n",
      "13.8386\n",
      "14.2977\n",
      "13.9978\n",
      "13.8988\n",
      "14.9958\n",
      "13.8311\n",
      "14.0619\n",
      "14.8985\n",
      "14.6437\n",
      "13.6302\n",
      "14.1046\n",
      "14.0292\n",
      "13.997\n",
      "12.4233\n",
      "14.2179\n",
      "14.1764\n",
      "15.9471\n",
      "13.1501\n",
      "13.73\n",
      "11.8339\n",
      "14.7914\n",
      "12.8241\n",
      "14.0821\n",
      "13.9922\n",
      "13.1992\n",
      "13.7091\n",
      "13.8971\n",
      "14.3924\n",
      "12.9877\n",
      "12.9533\n",
      "13.1732\n",
      "14.3396\n",
      "12.5522\n",
      "12.9584\n",
      "12.7167\n",
      "13.1454\n",
      "12.8666\n",
      "11.8714\n",
      "10.6804\n",
      "10.9688\n",
      "12.5292\n",
      "13.3727\n",
      "13.9122\n",
      "12.5819\n",
      "13.5261\n",
      "12.8544\n",
      "12.502\n",
      "13.0946\n",
      "12.2647\n",
      "11.8108\n",
      "11.4978\n",
      "12.706\n",
      "11.1177\n",
      "12.0285\n",
      "12.4667\n",
      "10.8551\n",
      "13.9399\n",
      "12.1149\n",
      "11.7624\n",
      "11.9991\n",
      "11.4208\n",
      "12.8516\n",
      "12.0684\n",
      "12.6952\n",
      "13.4461\n",
      "12.1864\n",
      "11.5743\n",
      "12.4308\n",
      "13.1161\n",
      "11.7429\n",
      "12.2482\n",
      "11.9814\n",
      "11.6938\n",
      "10.9542\n",
      "11.6454\n",
      "12.1281\n",
      "11.8254\n",
      "11.4601\n",
      "12.1281\n",
      "11.432\n",
      "12.0437\n",
      "10.5295\n",
      "12.0142\n",
      "10.8583\n",
      "12.9398\n",
      "10.7063\n",
      "11.8411\n",
      "13.5381\n",
      "11.842\n",
      "11.9196\n",
      "11.4221\n",
      "10.8467\n",
      "11.7584\n",
      "11.2169\n",
      "10.9802\n",
      "10.2234\n",
      "10.5426\n",
      "10.43\n",
      "10.9989\n",
      "9.5758\n",
      "13.6455\n",
      "10.6465\n",
      "9.38176\n",
      "11.2991\n",
      "10.7684\n",
      "9.92222\n",
      "9.07744\n",
      "10.4854\n",
      "10.0056\n",
      "9.32955\n",
      "11.1644\n",
      "11.0947\n",
      "10.4251\n",
      "11.1898\n",
      "10.3747\n",
      "8.62479\n",
      "10.3426\n",
      "8.89108\n",
      "10.1342\n",
      "10.3176\n",
      "10.3425\n",
      "9.50356\n",
      "10.4868\n",
      "9.8348\n",
      "10.2413\n",
      "9.66432\n",
      "9.30193\n",
      "9.64767\n",
      "10.3462\n",
      "9.77079\n",
      "9.38916\n",
      "9.28601\n",
      "10.4875\n",
      "9.68109\n",
      "10.3194\n",
      "10.2046\n",
      "9.53181\n",
      "8.9902\n",
      "8.21706\n",
      "8.84058\n",
      "10.9259\n",
      "9.70286\n",
      "9.51381\n",
      "9.51815\n",
      "8.62421\n",
      "10.0247\n",
      "9.49369\n",
      "9.59327\n",
      "9.41924\n",
      "8.37587\n",
      "8.75338\n",
      "9.07343\n",
      "8.96255\n",
      "9.60685\n",
      "8.97283\n",
      "9.9097\n",
      "8.08092\n",
      "9.49228\n",
      "9.31286\n",
      "9.85199\n",
      "8.87072\n",
      "9.17789\n",
      "9.49746\n",
      "7.98685\n",
      "9.34601\n",
      "8.27841\n",
      "8.80795\n",
      "8.78336\n",
      "8.89306\n",
      "8.71044\n",
      "8.18553\n",
      "8.69331\n",
      "8.3241\n",
      "8.84908\n",
      "8.90328\n",
      "8.45207\n",
      "7.8596\n",
      "8.09567\n",
      "8.77757\n",
      "8.52818\n",
      "8.46931\n",
      "8.83368\n",
      "8.555\n",
      "8.33551\n",
      "8.95401\n",
      "8.39291\n",
      "7.60979\n",
      "8.71373\n",
      "7.87675\n",
      "8.65533\n",
      "8.80261\n",
      "7.61182\n",
      "7.81732\n",
      "8.45879\n",
      "8.01141\n",
      "8.26937\n",
      "7.79552\n",
      "8.07071\n",
      "8.48294\n",
      "8.04479\n",
      "8.44778\n",
      "8.3032\n",
      "8.00924\n",
      "7.50311\n",
      "7.85447\n",
      "8.02473\n",
      "8.63555\n",
      "8.17347\n",
      "8.743\n",
      "7.47129\n",
      "7.19186\n",
      "7.35435\n",
      "7.02104\n",
      "7.78934\n",
      "7.41215\n",
      "7.09374\n",
      "7.83261\n",
      "7.59089\n",
      "7.50762\n",
      "7.41459\n",
      "6.90385\n",
      "6.94098\n",
      "7.32951\n",
      "7.02529\n",
      "7.22763\n",
      "7.583\n",
      "8.1006\n",
      "7.10509\n",
      "6.72066\n",
      "7.84797\n",
      "7.15828\n",
      "6.53398\n",
      "7.6401\n",
      "7.04079\n",
      "7.31402\n",
      "7.28816\n",
      "6.96014\n",
      "7.38963\n",
      "7.28674\n",
      "6.86678\n",
      "7.25827\n",
      "7.27643\n",
      "6.98382\n",
      "6.80173\n",
      "6.21987\n",
      "6.93343\n",
      "6.49547\n",
      "7.64824\n",
      "7.37287\n",
      "6.49151\n",
      "6.605\n",
      "6.39461\n",
      "6.24138\n",
      "7.13887\n",
      "6.20375\n",
      "6.40845\n",
      "5.85156\n",
      "7.03192\n",
      "7.16753\n",
      "5.98154\n",
      "6.61137\n",
      "6.89432\n",
      "6.47464\n",
      "5.61797\n",
      "6.3586\n",
      "6.92798\n",
      "6.22252\n",
      "7.03614\n",
      "6.06252\n",
      "6.84089\n",
      "7.08203\n",
      "5.98822\n",
      "6.7569\n",
      "6.27408\n",
      "6.977\n",
      "5.71371\n",
      "7.06078\n",
      "6.73784\n",
      "5.94864\n",
      "6.11921\n",
      "6.28054\n",
      "6.41001\n",
      "6.30064\n",
      "5.93318\n",
      "5.91476\n",
      "6.16898\n",
      "6.44016\n",
      "6.3581\n",
      "6.41955\n",
      "5.28502\n",
      "5.9485\n",
      "5.52972\n",
      "6.46834\n",
      "5.65893\n",
      "5.65472\n",
      "6.433\n",
      "6.06137\n",
      "6.72031\n",
      "5.75045\n",
      "6.0539\n",
      "5.76044\n",
      "5.64608\n",
      "5.77197\n",
      "6.05501\n",
      "5.81369\n",
      "5.81841\n",
      "6.19493\n",
      "5.65422\n",
      "5.27899\n",
      "6.16785\n",
      "5.39134\n",
      "5.72505\n",
      "6.07633\n",
      "5.44969\n",
      "5.51637\n",
      "5.66791\n",
      "5.2902\n",
      "5.99308\n",
      "5.27766\n",
      "4.89102\n",
      "5.21773\n",
      "5.20885\n",
      "5.73269\n",
      "5.06823\n",
      "5.33358\n",
      "5.36266\n",
      "5.32192\n",
      "5.07073\n",
      "5.12048\n",
      "5.35492\n",
      "5.23787\n",
      "5.56991\n",
      "5.32179\n",
      "4.98873\n",
      "5.85994\n",
      "5.33874\n",
      "4.89243\n",
      "5.28405\n",
      "5.09559\n",
      "5.36316\n",
      "5.23936\n",
      "5.41523\n",
      "5.20747\n",
      "5.41652\n",
      "5.10505\n",
      "5.11482\n",
      "4.52927\n",
      "4.95278\n",
      "5.12848\n",
      "5.16186\n",
      "4.7793\n",
      "5.21361\n",
      "4.99174\n",
      "4.85081\n",
      "5.45819\n",
      "5.15794\n",
      "5.2785\n",
      "5.28497\n",
      "5.17262\n",
      "4.90727\n",
      "4.58711\n",
      "4.60681\n",
      "4.87966\n",
      "4.68114\n",
      "5.36736\n",
      "4.85703\n",
      "4.6161\n",
      "4.56187\n",
      "5.18467\n",
      "4.60627\n",
      "4.65661\n",
      "4.43826\n",
      "4.8139\n",
      "4.55898\n",
      "4.68419\n",
      "4.7126\n",
      "4.38652\n",
      "4.34017\n",
      "4.61964\n",
      "4.80591\n",
      "4.56895\n",
      "4.32795\n",
      "4.55766\n",
      "4.33021\n",
      "4.42939\n",
      "4.82537\n",
      "4.4221\n",
      "4.30341\n",
      "4.63507\n",
      "4.38436\n",
      "4.46272\n",
      "4.38108\n",
      "3.91331\n",
      "4.09133\n",
      "4.20762\n",
      "4.12989\n",
      "4.42044\n",
      "4.54906\n",
      "4.06938\n",
      "4.04336\n",
      "4.11918\n",
      "4.36931\n",
      "4.35154\n",
      "4.31972\n",
      "4.043\n",
      "4.06367\n",
      "4.23985\n",
      "4.13548\n",
      "4.07282\n",
      "4.04096\n",
      "4.29852\n",
      "4.02707\n",
      "3.99971\n",
      "3.90553\n",
      "4.02489\n",
      "3.77985\n",
      "4.03727\n",
      "4.19379\n",
      "4.18932\n",
      "4.45414\n",
      "4.08647\n",
      "4.06713\n",
      "4.14413\n",
      "4.03588\n",
      "3.50701\n",
      "3.71975\n",
      "3.98581\n",
      "3.77864\n",
      "3.83279\n",
      "3.98747\n",
      "3.71369\n",
      "3.98384\n",
      "3.88266\n",
      "3.86796\n",
      "3.95744\n",
      "3.82564\n",
      "3.7422\n",
      "3.75776\n",
      "3.44135\n",
      "3.6421\n",
      "3.57269\n",
      "3.54772\n",
      "3.72539\n",
      "4.20999\n",
      "3.92598\n",
      "4.01728\n",
      "3.50815\n",
      "3.77492\n",
      "3.68346\n",
      "3.56324\n",
      "3.63441\n",
      "3.74308\n",
      "3.53452\n",
      "3.66178\n",
      "3.59296\n",
      "3.3166\n",
      "3.6278\n",
      "3.48374\n",
      "3.74252\n",
      "3.51063\n",
      "3.6819\n",
      "3.40911\n",
      "3.43086\n",
      "3.60183\n",
      "3.77429\n",
      "3.553\n",
      "3.46073\n",
      "3.54994\n",
      "3.51552\n",
      "3.33096\n",
      "3.5266\n",
      "3.40685\n",
      "3.64312\n",
      "3.68879\n",
      "3.30858\n",
      "3.60442\n",
      "3.4592\n",
      "3.39899\n",
      "3.55454\n",
      "3.59192\n",
      "3.28401\n",
      "3.47763\n",
      "3.15442\n",
      "3.18748\n",
      "3.11519\n",
      "3.16962\n",
      "3.29712\n",
      "3.28195\n",
      "3.0986\n",
      "3.5003\n",
      "3.30995\n",
      "3.33299\n",
      "3.27385\n",
      "3.29565\n",
      "3.26827\n",
      "3.45921\n",
      "3.13021\n",
      "3.05069\n",
      "3.11359\n",
      "3.09601\n",
      "3.28801\n",
      "3.3002\n",
      "3.09555\n",
      "3.20485\n",
      "3.20439\n",
      "3.0104\n",
      "2.98169\n",
      "3.03435\n",
      "3.03771\n",
      "3.05976\n",
      "2.94271\n",
      "3.37124\n",
      "3.19357\n",
      "3.12996\n",
      "2.99542\n",
      "3.15387\n",
      "3.20984\n",
      "3.23386\n",
      "3.18915\n",
      "2.84082\n",
      "3.00647\n",
      "2.99185\n",
      "2.83168\n",
      "2.77013\n",
      "3.1917\n",
      "3.07045\n",
      "3.03313\n",
      "3.159\n",
      "2.88676\n",
      "3.09622\n",
      "2.8632\n",
      "2.82008\n",
      "3.03854\n",
      "2.88126\n",
      "2.89012\n",
      "2.79737\n",
      "3.03752\n",
      "2.82821\n",
      "2.9123\n",
      "2.94386\n",
      "2.92096\n",
      "2.72505\n",
      "2.92658\n",
      "2.64564\n",
      "2.92905\n",
      "2.97998\n",
      "2.9068\n",
      "2.62818\n",
      "2.79155\n",
      "2.7911\n",
      "2.7987\n",
      "2.74476\n",
      "2.73121\n",
      "2.77693\n",
      "2.73567\n",
      "2.80761\n",
      "2.74967\n",
      "2.88898\n",
      "2.88947\n",
      "2.65019\n",
      "2.82071\n",
      "2.74559\n",
      "2.73078\n",
      "2.72232\n",
      "2.64188\n",
      "2.7615\n",
      "2.63315\n",
      "2.73342\n",
      "2.669\n",
      "2.64232\n",
      "2.74221\n",
      "2.71538\n",
      "2.66823\n",
      "2.64864\n",
      "2.725\n",
      "2.68012\n",
      "2.76295\n",
      "2.548\n",
      "2.66939\n",
      "2.63335\n",
      "2.56264\n",
      "2.65324\n",
      "2.59388\n",
      "2.69996\n",
      "2.62821\n",
      "2.52194\n",
      "2.63555\n",
      "2.661\n",
      "2.58322\n",
      "2.49481\n",
      "2.6107\n",
      "2.59405\n",
      "2.66874\n",
      "2.54569\n",
      "2.51093\n",
      "2.55296\n",
      "2.59732\n",
      "2.62404\n",
      "2.52835\n",
      "2.57552\n",
      "2.53796\n",
      "2.53529\n",
      "2.43143\n",
      "2.65736\n",
      "2.50515\n",
      "2.49949\n",
      "2.53858\n",
      "2.51821\n",
      "2.58282\n",
      "2.47784\n",
      "2.51508\n",
      "2.38657\n",
      "2.39185\n",
      "2.45011\n",
      "2.43216\n",
      "2.39444\n",
      "2.5314\n",
      "2.50251\n",
      "2.43204\n",
      "2.33761\n",
      "2.42643\n",
      "2.44932\n",
      "2.40979\n",
      "2.50212\n",
      "2.35451\n",
      "2.39744\n",
      "2.4147\n",
      "2.34355\n",
      "2.32449\n",
      "2.31553\n",
      "2.44224\n",
      "2.38969\n",
      "2.37887\n",
      "2.28287\n",
      "2.34489\n",
      "2.41959\n",
      "2.39043\n",
      "2.35103\n",
      "2.34347\n",
      "2.27508\n",
      "2.36613\n",
      "2.33249\n",
      "2.35257\n",
      "2.35843\n",
      "2.34088\n",
      "2.39928\n",
      "2.2843\n",
      "2.38641\n",
      "2.32437\n",
      "2.31093\n",
      "2.2431\n",
      "2.22147\n",
      "2.26921\n",
      "2.26286\n",
      "2.31941\n",
      "2.29989\n",
      "2.37534\n",
      "2.25759\n",
      "2.28912\n",
      "2.28574\n",
      "2.29218\n",
      "2.35387\n",
      "2.28936\n",
      "2.28035\n",
      "2.23323\n",
      "2.21887\n",
      "2.23355\n",
      "2.28846\n",
      "2.22265\n",
      "2.27561\n",
      "2.19771\n",
      "2.20058\n",
      "2.25759\n",
      "2.21511\n",
      "2.19419\n",
      "2.16205\n",
      "2.25623\n",
      "2.23152\n",
      "2.18585\n",
      "2.19816\n",
      "2.18123\n",
      "2.19018\n",
      "2.13512\n",
      "2.16937\n",
      "2.21428\n",
      "2.21065\n",
      "2.0778\n",
      "2.16131\n",
      "2.13731\n",
      "2.15397\n",
      "2.25799\n",
      "2.16786\n",
      "2.14261\n",
      "2.19318\n",
      "2.16804\n",
      "2.14856\n",
      "2.15646\n",
      "2.1766\n",
      "2.17809\n",
      "2.22925\n",
      "2.09121\n",
      "2.12204\n",
      "2.1881\n",
      "2.16787\n",
      "2.1422\n",
      "2.12812\n",
      "2.10889\n",
      "2.17781\n",
      "2.11084\n",
      "2.07745\n",
      "2.13209\n",
      "2.12005\n",
      "2.12385\n",
      "2.05301\n",
      "2.10133\n",
      "2.12946\n",
      "2.10445\n",
      "2.0928\n",
      "2.11051\n",
      "2.08685\n",
      "2.07347\n",
      "2.07303\n",
      "2.03982\n",
      "2.12014\n",
      "2.05951\n",
      "2.05171\n",
      "2.05729\n",
      "2.0958\n",
      "2.08097\n",
      "2.13941\n",
      "2.04329\n",
      "2.0932\n",
      "2.00755\n",
      "2.07076\n",
      "2.0731\n",
      "2.03418\n",
      "1.99405\n",
      "2.01748\n",
      "2.04609\n",
      "2.05485\n",
      "2.04346\n",
      "2.02316\n",
      "2.00043\n",
      "2.03871\n",
      "1.99442\n",
      "2.0203\n",
      "2.00388\n",
      "2.01982\n",
      "[array([[  4.99806929e+00],\n",
      "       [  4.50359483e-04],\n",
      "       [  3.11280918e+00]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholders are used to feed values from python to TensorFlow ops. We define\n",
    "# two placeholders, one for input feature x, and one for output y.\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Assuming we know that the desired function is a polynomial of 2nd degree, we\n",
    "# allocate a vector of size 3 to hold the coefficients. The variable will be\n",
    "# automatically initialized with random noise.\n",
    "w = tf.get_variable(\"w\", shape=[3, 1])\n",
    "\n",
    "# We define yhat to be our estimate of y.\n",
    "f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)\n",
    "yhat = tf.squeeze(tf.matmul(f, w), 1)\n",
    "\n",
    "# The loss is defined to be the l2 distance between our estimate of y and its\n",
    "# true value. We also added a shrinkage term, to ensure the resulting weights\n",
    "# would be small.\n",
    "loss = tf.nn.l2_loss(yhat - y) + 0.1 * tf.nn.l2_loss(w)\n",
    "\n",
    "# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.\n",
    "train_op = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "\n",
    "def generate_data():\n",
    "    x_val = np.random.uniform(-10.0, 10.0, size=100)\n",
    "    y_val = 5 * np.square(x_val) + 3\n",
    "    return x_val, y_val\n",
    "\n",
    "sess = tf.Session()\n",
    "# Since we are using variables we first need to initialize them.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for _ in range(1000):\n",
    "    x_val, y_val = generate_data()\n",
    "    _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})\n",
    "    print(loss_val)\n",
    "print(sess.run([w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   1,    1,    2,    3,    5,    8,   13,   21,   34,   55,   89,\n",
      "        144,  233,  377,  610,  987, 1597, 2584, 4181, 6765], dtype=int32), 20)\n"
     ]
    }
   ],
   "source": [
    "n = tf.constant(20)\n",
    "\n",
    "c = tf.TensorArray(tf.int32, n)\n",
    "c = c.write(0, 1)\n",
    "c = c.write(1, 1)\n",
    "\n",
    "def cond(i, a, b, c):\n",
    "    return i < n\n",
    "\n",
    "def body(i, a, b, c):\n",
    "    c = c.write(i, a + b)\n",
    "    return i + 1, b, a + b, c\n",
    "\n",
    "i, a, b, c = tf.while_loop(cond, body, (2, 1, 1, c))\n",
    "\n",
    "#print tf.Session().run(c)\n",
    "\n",
    "d = c.stack()\n",
    "\n",
    "print(tf.Session().run(d), tf.Session().run(c.size()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
