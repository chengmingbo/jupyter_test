{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[ 4.  3.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "v1 = tf.constant([1., 2., 3., 4.])\n",
    "v2 = tf.constant([4., 3., 2., 1.])\n",
    "sess = tf.InteractiveSession()\n",
    "print tf.greater(v1, v2).eval()\n",
    "print tf.where(tf.greater(v1, v2), v1, v2).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name=\"y-input\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,1], stddev=1, seed=1))\n",
    "y = tf.matmul(x, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_less = 1\n",
    "loss_more = 1000\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y-y_)*loss_more, (y_-y) * loss_less ))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps:\n",
      "[[-0.81231821]\n",
      " [ 1.48359871]]\n",
      "1000 steps:\n",
      "[[-1.00663936]\n",
      " [ 0.99975079]]\n",
      "2000 steps:\n",
      "[[-0.89243895]\n",
      " [ 0.97022849]]\n",
      "3000 steps:\n",
      "[[-0.67336702]\n",
      " [ 0.96329486]]\n",
      "4000 steps:\n",
      "[[-0.32197747]\n",
      " [ 0.9526661 ]]\n",
      "4999 steps:\n",
      "[[ 0.19476356]\n",
      " [ 0.93936056]]\n",
      "foward propagation: [[ 0.00744597]]\n"
     ]
    }
   ],
   "source": [
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "Y = [[x1+x2+rdm.rand()/10.0-0.05] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    batch_size = 8\n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size) % dataset_size\n",
    "        end = min(start+batch_size, dataset_size)\n",
    "        sess.run(train_step, feed_dict={x:X[start:end], y_:Y[start:end]})\n",
    "        if i%1000 == 0:\n",
    "            print i, \"steps:\\n\", sess.run(w1)\n",
    "    print i, \"steps:\\n\", sess.run(w1)\n",
    "    ww = sess.run(w1)\n",
    "\n",
    "    print \"foward propagation:\", sess.run(tf.matmul(x, ww), feed_dict={x:[[-0.01, 0.01]]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
